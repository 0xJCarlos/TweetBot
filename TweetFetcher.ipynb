{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TweetFetcher.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3fXO/ogjxtrLv9Vwmmvy0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0xJCarlos/TweetBot/blob/main/TweetFetcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tweet Fetcher\n",
        "This is where the project begins, we need data to do everything in this project, and this is where we get that Data.\n",
        "\n",
        "We use the Tweepy library to get the tweets, the JSON library to manage the tweets to store them, and pandas to organize and store the tweets inside a DataFrame and then put them inside a .csv file. "
      ],
      "metadata": {
        "id": "TD5hisngQPJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 0: Install Tweepy\n",
        "!pip install tweepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb1-jmEAq7k3",
        "outputId": "28563b48-e597-43ae-ce2c-bae195a4dea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 0.1: Import all the libraries into our project\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import csv"
      ],
      "metadata": {
        "id": "q4fXbB7EwyWk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 0.2: Authentificate into the Twitter API with the Tweepy library\n",
        "#DELETE THE VALUES WHEN MAKING THE REPO PUBLIC\n",
        "consumer_key = \"0P9DjdpkFKPVfZfpE7qDI7hQb\"\n",
        "consumer_secret = \"RfKuIsLYISTQwlrKefIt7HLajcRdH78zHxp7FyAoVnTAiO03ay\"\n",
        "access_token = \"1194443793317056512-QDGtnRJ5mgEsHno3j6grLAKhmYCBqv\"\n",
        "access_token_secret = \"1mSWwkftAUlHizzITbdermR8xg98Gseg6roxPQCAARQWS\""
      ],
      "metadata": {
        "id": "y8hT-OOArJgT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7m0hcNj4M72"
      },
      "source": [
        "#Step 1: Create the API's Objects\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) #Create the authentification object\n",
        "\n",
        "auth.set_access_token(access_token, access_token_secret ) #Configure the Access Token and Access Token Secret\n",
        "\n",
        "#Create the API Object passing the auth info, we also wait on rate limit because the API puts us on hold for some minutes when doing too many requests\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Create the fetchTweets function to put the tweets inside a text file\n",
        "lista = [] \n",
        "def fetchTweet(tuits):\n",
        "    for each_tweet in tuits: \n",
        "      lista.append(each_tweet._json) #saves every tweet inside the list, in json format\n",
        "\n",
        "    with open('tweets_json.json','w') as file:  #writes the contents of the list as a json file\n",
        "      file.write(json.dumps(lista, indent=4))"
      ],
      "metadata": {
        "id": "z1_ejrMZ1LLv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Variables to request the last 2000 tweets from different accounts, filtering retweets too. Maybe i could use a function or a constructor to clean some of this lol\n",
        "igntweets = tweepy.Cursor(api.user_timeline, screen_name = 'IGN', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "kotakutweets = tweepy.Cursor(api.user_timeline, screen_name = 'kotaku', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "polygontweets = tweepy.Cursor(api.user_timeline, screen_name = 'polygon', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "engadgettweets = tweepy.Cursor(api.user_timeline, screen_name = 'engadgetgaming', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "eurogamertweets = tweepy.Cursor(api.user_timeline, screen_name = 'eurogamer', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "gamesindustrytweets = tweepy.Cursor(api.user_timeline, screen_name = 'GIBiz', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "gamedevtweets = tweepy.Cursor(api.user_timeline, screen_name = 'gamedevdotcom', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "destructoidtweets = tweepy.Cursor(api.user_timeline, screen_name = 'destructoid', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "vg247tweets = tweepy.Cursor(api.user_timeline, screen_name = 'VG247', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "vgctweets = tweepy.Cursor(api.user_timeline, screen_name = 'VGC_News', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "gamesbeattweets = tweepy.Cursor(api.user_timeline, screen_name = 'GamesBeat', q='-filter:retweets', tweet_mode=\"extended\").items(2000)\n",
        "rockpapershottweets = tweepy.Cursor(api.user_timeline, screen_name = 'rockpapershot', q='-filter:retweets', tweet_mode=\"extended\").items(2000) \n",
        "\n",
        "accounts=[igntweets,kotakutweets,polygontweets,engadgettweets,eurogamertweets,gamesindustrytweets,gamedevtweets,destructoidtweets,vgctweets,vg247tweets,gamesbeattweets,rockpapershottweets]\n"
      ],
      "metadata": {
        "id": "DNV0rviRgfF4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Fetch the tweets\n",
        "for tweet in accounts:\n",
        "  fetchTweet(tweet)"
      ],
      "metadata": {
        "id": "ZsSDfGu22DrM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5: read the .json file and convert to csv for further use.\n",
        "df = pd.read_json('/content/tweets_json.json') \n",
        "\n",
        "df.to_csv('tweets.csv')"
      ],
      "metadata": {
        "id": "oogTCUzDM4ME"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}